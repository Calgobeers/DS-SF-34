{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-34 | 05 | _k_-Nearest Neighbors | Assignment | Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _k_-Nearest Neighbors on the Boston Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "from sklearn import preprocessing, neighbors, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-05-boston.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>...</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>...</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX  ...   TAX  PTRATIO   BLACK  LSTAT  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  ...   296     15.3  396.90   4.98   \n",
       "1    0.02731   0.0   7.07     0  0.469  ...   242     17.8  396.90   9.14   \n",
       "2    0.02729   0.0   7.07     0  0.469  ...   242     17.8  392.83   4.03   \n",
       "3    0.03237   0.0   2.18     0  0.458  ...   222     18.7  394.63   2.94   \n",
       "4    0.06905   0.0   2.18     0  0.458  ...   222     18.7  396.90   5.33   \n",
       "..       ...   ...    ...   ...    ...  ...   ...      ...     ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  ...   273     21.0  391.99   9.67   \n",
       "502  0.04527   0.0  11.93     0  0.573  ...   273     21.0  396.90   9.08   \n",
       "503  0.06076   0.0  11.93     0  0.573  ...   273     21.0  396.90   5.64   \n",
       "504  0.10959   0.0  11.93     0  0.573  ...   273     21.0  393.45   6.48   \n",
       "505  0.04741   0.0  11.93     0  0.573  ...   273     21.0  396.90   7.88   \n",
       "\n",
       "     MEDV  \n",
       "0    24.0  \n",
       "1    21.6  \n",
       "2    34.7  \n",
       "3    33.4  \n",
       "4    36.2  \n",
       "..    ...  \n",
       "501  22.4  \n",
       "502  20.6  \n",
       "503  23.9  \n",
       "504  22.0  \n",
       "505  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston dataset concerns itself with housing values in suburbs of Boston.  A description of the dataset is as follows:\n",
    "\n",
    "- CRIM: per capita crime rate by town\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sqft\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River binary/dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX: nitric oxides concentration (parts per 10 million)\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centers\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate (per ten thousands of dollars)\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT: % lower status of the population\n",
    "- MEDV: Median value of owner-occupied homes (in thousands of dollars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 1.  Let's first categorize `MEDV` to 4 groups: Bottom 20% as Level 1, next 30% as Level 2, next 30% categorized as Level 3, and the top 20% as Level 4.  Please create a new variable `MEDV_Category` that stores the level number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_2 = ((df.MEDV > df.MEDV.quantile(.2)) & (df.MEDV <= df.MEDV.quantile(.5)))\n",
    "level_3 = ((df.MEDV > df.MEDV.quantile(.5)) & (df.MEDV <= df.MEDV.quantile(.8)))\n",
    "level_4 = (df.MEDV > df.MEDV.quantile(.8))\n",
    "\n",
    "df['MEDV_Category'] = '1'\n",
    "df.loc[level_2, 'MEDV_Category'] = '2'\n",
    "df.loc[level_3, 'MEDV_Category'] = '3'\n",
    "df.loc[level_4, 'MEDV_Category'] = '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our goal is to predict `MEDV_Category` based on `RM`, `PTRATIO`, and `LSTAT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 2.  First normalize `RM`, `PTRATIO`, and `LSTAT`.  By normalizing, we mean to scale each variable between 0 and 1 with the lowest value as 0 and the highest value as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>...</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>MEDV_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX      ...        PTRATIO   BLACK  LSTAT  \\\n",
       "0    0.00632  18.0   2.31     0  0.538      ...           15.3  396.90   4.98   \n",
       "1    0.02731   0.0   7.07     0  0.469      ...           17.8  396.90   9.14   \n",
       "2    0.02729   0.0   7.07     0  0.469      ...           17.8  392.83   4.03   \n",
       "3    0.03237   0.0   2.18     0  0.458      ...           18.7  394.63   2.94   \n",
       "4    0.06905   0.0   2.18     0  0.458      ...           18.7  396.90   5.33   \n",
       "..       ...   ...    ...   ...    ...      ...            ...     ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573      ...           21.0  391.99   9.67   \n",
       "502  0.04527   0.0  11.93     0  0.573      ...           21.0  396.90   9.08   \n",
       "503  0.06076   0.0  11.93     0  0.573      ...           21.0  396.90   5.64   \n",
       "504  0.10959   0.0  11.93     0  0.573      ...           21.0  393.45   6.48   \n",
       "505  0.04741   0.0  11.93     0  0.573      ...           21.0  396.90   7.88   \n",
       "\n",
       "     MEDV  MEDV_Category  \n",
       "0    24.0              3  \n",
       "1    21.6              3  \n",
       "2    34.7              4  \n",
       "3    33.4              4  \n",
       "4    36.2              4  \n",
       "..    ...            ...  \n",
       "501  22.4              3  \n",
       "502  20.6              2  \n",
       "503  23.9              3  \n",
       "504  22.0              3  \n",
       "505  11.9              1  \n",
       "\n",
       "[506 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[ ['RM', 'PTRATIO', 'LSTAT'] ]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57750527,  0.28723404,  0.08967991],\n",
       "       [ 0.5479977 ,  0.55319149,  0.2044702 ],\n",
       "       [ 0.6943859 ,  0.55319149,  0.06346578],\n",
       "       ..., \n",
       "       [ 0.65433991,  0.89361702,  0.10789183],\n",
       "       [ 0.61946733,  0.89361702,  0.13107064],\n",
       "       [ 0.47307913,  0.89361702,  0.16970199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 3.  Run a _k_-Nearest Neighbor classifier with 5 nearest neighbors and report your misclassification error; set `weights` to `uniform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2134387351778656"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = df.MEDV_Category\n",
    "\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = 5, weights = 'uniform').fit(X, c)\n",
    "\n",
    "accuracy = model.score(X, c)\n",
    "misclassification_error = 1 - accuracy\n",
    "\n",
    "misclassification_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ~0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 4.  Is this error reliable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No, this is a training error and can be skewed due to overfitting.  This is not a validation or cross-validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 5.  Now use 10-fold cross-validation to choose the most efficient `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 7...435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(X, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73122529644268774"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 17}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.660079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.679842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.711462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.699605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>0.264822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>0.264822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>452</td>\n",
       "      <td>0.264822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>453</td>\n",
       "      <td>0.264822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>454</td>\n",
       "      <td>0.262846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       k     score\n",
       "0      1  0.638340\n",
       "1      2  0.660079\n",
       "2      3  0.679842\n",
       "3      4  0.711462\n",
       "4      5  0.699605\n",
       "..   ...       ...\n",
       "449  450  0.264822\n",
       "450  451  0.264822\n",
       "451  452  0.264822\n",
       "452  453  0.264822\n",
       "453  454  0.262846\n",
       "\n",
       "[454 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({'k': [cv_result['n_neighbors'] for cv_result in gs.cv_results_['params']],\n",
    "    'score': gs.cv_results_['mean_test_score']})\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAENCAYAAAD0eSVZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df.plot(x = 'k', y = 'score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 6.  Explain your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It seems like `k = 22` produces the best result with an accuracy close to 70%. This accuracy is less than what we found before but way more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 7.  Train your model with the optimal `k` you found above (don't worry if it changes from time to time - if that is the case use the one that is usually the best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25296442687747034"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 22, weights = 'uniform').fit(X, c)\n",
    "\n",
    "accuracy = model.score(X, c)\n",
    "misclassification_error = 1 - accuracy\n",
    "\n",
    "misclassification_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ~ 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 8.  After training your model with that `k`, use it to predict the class of a neighborhood with `RM = 2`, `PRATIO = 19`, and `LSTAT = 3.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X = [ [2, 19, 3.5] ]\n",
    "predict_X = scaler.transform(predict_X)\n",
    "\n",
    "predict_y = model.predict(predict_X)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}